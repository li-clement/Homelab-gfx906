{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72002520-3cd5-498f-8160-235c32c559c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ç‰ˆæœ¬: 3.12.3\n",
      "------------------------------\n",
      "âŒ vllm            : æœªå®‰è£…\n",
      "âœ… numpy           : 2.4.1\n",
      "âŒ scipy           : æœªå®‰è£…\n",
      "âœ… transformers    : 5.0.0.dev0\n",
      "âœ… torch           : 2.5.1+rocm6.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "def check_version(package_name):\n",
    "    try:\n",
    "        lib = importlib.import_module(package_name)\n",
    "        print(f\"âœ… {package_name:<15} : {lib.__version__}\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package_name:<15} : æœªå®‰è£…\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {package_name:<15} : å¯¼å…¥å‡ºé”™ ({e})\")\n",
    "\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# æ£€æŸ¥æ ¸å¿ƒä¾èµ–\n",
    "pkgs = ['vllm', 'numpy', 'scipy', 'transformers', 'torch']\n",
    "for pkg in pkgs:\n",
    "    check_version(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7d016-6065-4a26-bf5e-204d4b470368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================\n",
    "ENV_NAME = \"env_glm\"\n",
    "DISPLAY_NAME = \"ğŸ¨ GLM-Image (Artist)\"\n",
    "\n",
    "# éœ€è¦å®‰è£…çš„ç»˜å›¾ä¾èµ– (å®Œå…¨ä¸å« torch)\n",
    "# æ³¨æ„ï¼šæˆ‘ä»¬å°†å¼ºåˆ¶å®‰è£… numpy 1.26.4 åˆ°è¿™ä¸ªè™šæ‹Ÿç¯å¢ƒé‡Œï¼Œ\n",
    "# è¿™æ ·å®ƒä¼šâ€œé®æŒ¡â€ä½ç³»ç»ŸåŸæœ¬çš„ numpy 2.1ï¼Œä½†ä¸ä¼šå½±å“ç³»ç»ŸåŸæœ¬çš„ torchã€‚\n",
    "requirements = [\n",
    "    \"numpy==1.26.4\", \n",
    "    \"diffusers\", \n",
    "    \"transformers\", \n",
    "    \"accelerate\", \n",
    "    \"sentencepiece\", \n",
    "    \"opencv-python-headless\", \n",
    "    \"pillow\", \n",
    "    \"ipykernel\"\n",
    "]\n",
    "\n",
    "# ================= ğŸš€ è‡ªåŠ¨åŒ–è„šæœ¬ =================\n",
    "\n",
    "def run_cmd(cmd, desc):\n",
    "    print(f\"â³ {desc}...\")\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True, executable=\"/bin/bash\")\n",
    "        print(\"   âœ… æˆåŠŸ\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   âŒ å¤±è´¥: {e}\")\n",
    "        raise\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹æ„å»º GLM-Image ç¯å¢ƒ (ç»§æ‰¿ç°æœ‰ PyTorch)...\\n\")\n",
    "\n",
    "# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (å…³é”®å‚æ•°: --system-site-packages)\n",
    "# è¿™ä¼šè®©æ–°ç¯å¢ƒç›´æ¥â€œçœ‹åˆ°â€æ‚¨åŸºç¡€ç¯å¢ƒé‡Œçš„ PyTorchï¼Œè€Œä¸éœ€è¦é‡æ–°å®‰è£…\n",
    "if not os.path.exists(ENV_NAME):\n",
    "    cmd_venv = f\"{sys.executable} -m venv {ENV_NAME} --system-site-packages\"\n",
    "    run_cmd(cmd_venv, \"åˆ›å»ºç»§æ‰¿å¼è™šæ‹Ÿç¯å¢ƒ\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ ç¯å¢ƒç›®å½• {ENV_NAME} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º\")\n",
    "\n",
    "# è·å–è·¯å¾„\n",
    "env_bin = os.path.abspath(os.path.join(ENV_NAME, \"bin\"))\n",
    "env_pip = os.path.join(env_bin, \"pip\")\n",
    "env_python = os.path.join(env_bin, \"python\")\n",
    "\n",
    "# 2. å±€éƒ¨å®‰è£… Numpy 1.26 (å…³é”®æ­¥éª¤)\n",
    "# ä½¿ç”¨ --ignore-installed å¼ºåˆ¶åœ¨è™šæ‹Ÿç¯å¢ƒé‡Œè£…ä¸€ä¸ªæ—§ç‰ˆ numpy\n",
    "# è¿™å°±åƒç»™æ–°ç¯å¢ƒæˆ´äº†ä¸€å‰¯çœ¼é•œï¼Œè®©å®ƒçœ‹åˆ°çš„æ˜¯ 1.26ï¼Œè€Œä¸æ˜¯ç³»ç»Ÿçš„ 2.1\n",
    "print(f\"â³ æ­£åœ¨é…ç½®å…¼å®¹æ€§ Numpy...\")\n",
    "cmd_numpy = f\"{env_pip} install numpy==1.26.4 --ignore-installed\"\n",
    "run_cmd(cmd_numpy, \"Numpy 1.26.4 è¦†ç›–å®‰è£…\")\n",
    "\n",
    "# 3. å®‰è£… Diffusers ç­‰åº“\n",
    "# pip ä¼šæ£€æµ‹åˆ°ç³»ç»Ÿé‡Œå·²ç»æœ‰ torch äº†ï¼Œæ‰€ä»¥å®ƒåªéœ€å®‰è£…å‰©ä¸‹çš„åº“\n",
    "pkgs_str = \" \".join(requirements[1:]) # è·³è¿‡åˆ—è¡¨ç¬¬ä¸€ä¸ªnumpy(å·²è£…)\n",
    "print(f\"â³ å®‰è£…ç»˜å›¾ä¾èµ– (Diffusers, Transformers)...\")\n",
    "cmd_deps = f\"{env_pip} install {pkgs_str}\"\n",
    "run_cmd(cmd_deps, \"ä¾èµ–åº“å®‰è£…\")\n",
    "\n",
    "# 4. æ³¨å†Œå†…æ ¸\n",
    "cmd_kernel = f'{env_python} -m ipykernel install --user --name={ENV_NAME} --display-name \"{DISPLAY_NAME}\"'\n",
    "run_cmd(cmd_kernel, \"å†…æ ¸æ³¨å†Œ\")\n",
    "\n",
    "# 5. æœ€ç»ˆéªŒè¯\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ” éªŒè¯ç¯å¢ƒéš”ç¦»æ€§ä¸ç»§æ‰¿æ€§...\")\n",
    "verify_script = \"\"\"\n",
    "import torch\n",
    "import numpy\n",
    "import sys\n",
    "\n",
    "print(f'Python è·¯å¾„: {sys.executable}')\n",
    "print(f'PyTorch ç‰ˆæœ¬: {torch.__version__} (ç»§æ‰¿è‡ªç³»ç»Ÿ)')\n",
    "print(f'ROCm çŠ¶æ€:    {torch.version.hip}')\n",
    "print(f'Numpy ç‰ˆæœ¬:   {numpy.__version__} (è™šæ‹Ÿç¯å¢ƒç‹¬æœ‰)')\n",
    "\n",
    "# æ£€æŸ¥é€»è¾‘\n",
    "if 'rocm' not in torch.__version__ and not torch.version.hip and 'git' not in torch.__version__:\n",
    "     # æ³¨ï¼šæ‚¨çš„ç‰ˆæœ¬å« git å­—ç¬¦ï¼Œæ‰€ä»¥åŠ ä¸ªåˆ¤æ–­\n",
    "    print('âš ï¸ è­¦å‘Šï¼šPyTorch æ¥æºçœ‹èµ·æ¥ä¸å¯¹ï¼Œè¯·æ£€æŸ¥ã€‚')\n",
    "elif numpy.__version__ != '1.26.4':\n",
    "    print('âŒ é”™è¯¯ï¼šNumpy ç‰ˆæœ¬æ²¡é”ä½ï¼')\n",
    "else:\n",
    "    print('âœ… å®Œç¾ï¼æˆåŠŸå¤ç”¨äº†ç³»ç»Ÿçš„ ROCm PyTorchï¼ŒåŒæ—¶ä½¿ç”¨äº†å…¼å®¹çš„ Numpy 1.26ã€‚')\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    subprocess.run([env_python, \"-c\", verify_script], check=True)\n",
    "    print(\"ğŸ‰ğŸ‰ğŸ‰ ç¯å¢ƒæ„å»ºå®Œæˆï¼è¯·åˆ·æ–°é¡µé¢åˆ‡æ¢å†…æ ¸ã€‚\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"âŒ éªŒè¯è„šæœ¬æŠ¥é”™ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c380d-f996-48f5-9e45-baf4ba2cdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# ================= ğŸ”§ é…ç½® =================\n",
    "# 1. å¼ºåˆ¶ä½¿ç”¨å›½å†…é•œåƒ (HF-Mirror)\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "# 2. å®šä¹‰ä¸‹è½½è·¯å¾„\n",
    "repo_id = \"zai-org/GLM-Image\"\n",
    "local_model_path = \"/workspace/models/GLM-Image\"\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹ä» hf-mirror.com ä¸‹è½½æ¨¡å‹: {repo_id}\")\n",
    "print(f\"ğŸ“‚ ç›®æ ‡ä¿å­˜è·¯å¾„: {local_model_path}\")\n",
    "print(\"âš ï¸ æ¨¡å‹ä½“ç§¯çº¦ 30GB+ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "try:\n",
    "    # ================= ğŸ“¥ å¼€å§‹ä¸‹è½½ =================\n",
    "    # snapshot_download æ˜¯ Python ç‰ˆçš„ \"huggingface-cli download\"\n",
    "    snapshot_download(\n",
    "        repo_id=repo_id,\n",
    "        local_dir=local_model_path,\n",
    "        local_dir_use_symlinks=False, # ç›´æ¥ä¸‹è½½æ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹\n",
    "        resume_download=True,         # æ”¯æŒæ–­ç‚¹ç»­ä¼ \n",
    "        max_workers=8                 # å¤šçº¿ç¨‹åŠ é€Ÿ\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸï¼\")\n",
    "    print(f\"ä½ ç°åœ¨å¯ä»¥è¿è¡Œ [ç¬¬ 3 æ­¥] åŠ è½½æ¨¡å‹äº†ã€‚\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nâŒ æŠ¥é”™ï¼šç¼ºå°‘ huggingface_hub åº“ã€‚\")\n",
    "    print(\"è¯·å…ˆè¿è¡Œ: !pip install huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ä¸‹è½½å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ æç¤º: ç½‘ç»œå¯èƒ½ä¸­æ–­ï¼Œè¯·ç›´æ¥é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼ç»§ç»­ä¸‹è½½ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad4040-dc87-4371-94cc-c45b84fbc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸ—‘ï¸ æ­£åœ¨å¸è½½ bitsandbytes (å®ƒæ˜¯å¯¼è‡´æŠ¥é”™çš„å…ƒå‡¶)...\")\n",
    "os.system(\"pip uninstall bitsandbytes -y\")\n",
    "print(\"âœ… å¸è½½å®Œæˆï¼\")\n",
    "\n",
    "# âš ï¸ å…³é”®ï¼šä¸ºäº†ç¡®ä¿ Python é‡æ–°åŠ è½½ç¯å¢ƒï¼Œå»ºè®®é‡å¯å†…æ ¸\n",
    "# ä½†å¦‚æœä¸æƒ³é‡å¯ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•ç»§ç»­è¿è¡Œä¸‹ä¸€æ­¥ï¼Œé€šå¸¸ä¹Ÿæ²¡é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e35696-5016-4a02-b305-e65f238586b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "print(\"ğŸš‘ æ­£åœ¨ä¿®å¤åº“ç‰ˆæœ¬å†²çª...\")\n",
    "\n",
    "# 1. å¸è½½å¯èƒ½å†²çªçš„æ—§ç‰ˆ peft\n",
    "os.system(\"pip uninstall peft -y\")\n",
    "\n",
    "# 2. ä» GitHub æºç å®‰è£…æœ€æ–°ç‰ˆ peft (ä½¿ç”¨åŠ é€Ÿé•œåƒ)\n",
    "# è¿™æ ·èƒ½ç¡®ä¿å®ƒå’Œ transformers 5.0.0.dev0 å®Œç¾å…¼å®¹\n",
    "exit_code = os.system(\"pip install git+https://gh-proxy.org/https://github.com//huggingface/peft.git -i https://pypi.tuna.tsinghua.edu.cn/simple\")\n",
    "\n",
    "if exit_code == 0:\n",
    "    print(\"\\nâœ… PEFT ä¿®å¤æˆåŠŸï¼\")\n",
    "    print(\"âš ï¸ å…³é”®æç¤ºï¼šä¸ºäº†åº”ç”¨æ›´æ”¹ï¼Œè¯·åŠ¡å¿…ã€é‡å¯å†…æ ¸ã€‘(Restart Kernel)ï¼\")\n",
    "    print(\"   (åœ¨ Notebook èœå•æ ç‚¹å‡»ï¼šKernel -> Restart Kernel)\")\n",
    "else:\n",
    "    print(\"\\nâŒ PEFT å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a129db-53f5-4ea8-93ac-dd25260decd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸš‘ æ­£åœ¨ä¿®å¤ Tokenizer ä¾èµ–...\")\n",
    "\n",
    "# 1. å¼ºåˆ¶å‡çº§ mistral_common åˆ°æœ€æ–°ç‰ˆ\n",
    "# 2. åŒæ—¶æ›´æ–° tiktoken (GLM-Image å¼ºä¾èµ–è¿™ä¸ª)\n",
    "os.system(\"pip install -U mistral_common tiktoken -i https://pypi.tuna.tsinghua.edu.cn/simple\")\n",
    "\n",
    "print(\"âœ… ä¿®å¤å®Œæˆï¼\")\n",
    "print(\"âš ï¸ è¯·åŠ¡å¿…ã€é‡å¯å†…æ ¸ (Restart Kernel)ã€‘åå†è¿è¡Œä¸‹ä¸€æ­¥ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b602ac7-94f6-480b-b121-a1f353f28c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸš‘ æ­£åœ¨æ‰§è¡Œæ·±åº¦ä¿®å¤ (Deep Repair)...\")\n",
    "print(\"ğŸ”„ æ­£åœ¨åˆ‡æ¢é•œåƒæºè‡³: https://gh-proxy.org/\")\n",
    "\n",
    "# 1. ğŸ—‘ï¸ å¸è½½å†²çªåŒ… (æ¸…ç†æ—§ç¯å¢ƒ)\n",
    "# å¿…é¡»æŠŠ bitsandbytes å¸è½½æ‰ï¼Œå¦åˆ™ä¼šæŠ¥ ROCm é”™è¯¯\n",
    "pkgs_to_remove = \"bitsandbytes peft transformers diffusers accelerate\"\n",
    "print(f\"   â†³ æ­£åœ¨å¸è½½æ—§ç‰ˆæœ¬: {pkgs_to_remove} ...\")\n",
    "os.system(f\"pip uninstall -y {pkgs_to_remove}\")\n",
    "\n",
    "# 2. ğŸ“¦ é‡æ–°å®‰è£… (ä½¿ç”¨æ–°é•œåƒæº)\n",
    "print(\"   â†³ æ­£åœ¨ä»æºç é‡æ–°å®‰è£…ä¾èµ– (è¯·è€å¿ƒç­‰å¾…)...\")\n",
    "\n",
    "install_cmds = [\n",
    "    # åŸºç¡€ä¾èµ– (èµ°æ¸…åæº)\n",
    "    \"pip install -U huggingface_hub sentencepiece protobuf requests -i https://pypi.tuna.tsinghua.edu.cn/simple\",\n",
    "    \n",
    "    # æ ¸å¿ƒåº“ (èµ° gh-proxy.org åŠ é€Ÿ)\n",
    "    # æ³¨æ„ï¼špeft å¿…é¡»è£…å¼€å‘ç‰ˆæ‰èƒ½é…åˆæœ€æ–°çš„ transformers\n",
    "    \"pip install git+https://gh-proxy.org/https://github.com/huggingface/peft.git\",\n",
    "    \"pip install git+https://gh-proxy.org/https://github.com/huggingface/accelerate.git\",\n",
    "    \"pip install git+https://gh-proxy.org/https://github.com/huggingface/transformers.git\",\n",
    "    \"pip install git+https://gh-proxy.org/https://github.com/huggingface/diffusers.git\"\n",
    "]\n",
    "\n",
    "for cmd in install_cmds:\n",
    "    print(f\"      æ‰§è¡Œ: {cmd}\")\n",
    "    os.system(cmd)\n",
    "\n",
    "print(\"\\nâœ… ç¯å¢ƒä¿®å¤å®Œæˆï¼\")\n",
    "print(\"âš ï¸âš ï¸âš ï¸ è¯·åŠ¡å¿…ç‚¹å‡»ä¸Šæ–¹èœå•æ ã€Kernel -> Restart Kernelã€‘é‡å¯å†…æ ¸ï¼âš ï¸âš ï¸âš ï¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c347c-dcbb-4709-adbb-2a18d41dc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸš‘ æ­£åœ¨ç§»é™¤å†²çªçš„ Mistral ä¾èµ–åº“...\")\n",
    "# å¼ºåˆ¶å¸è½½ mistral_commonï¼Œå®ƒé˜»ç¢äº† GLM-Image çš„åŠ è½½\n",
    "os.system(\"pip uninstall -y mistral_common\")\n",
    "\n",
    "print(\"âœ… å†²çªå·²æ¸…é™¤ï¼\")\n",
    "print(\"âš ï¸âš ï¸âš ï¸ä»¥æ­¤ä¸ºç•Œï¼šè¯·åŠ¡å¿…ç‚¹å‡»ä¸Šæ–¹èœå•ã€Kernel -> Restart Kernelã€‘é‡å¯å†…æ ¸ï¼âš ï¸âš ï¸âš ï¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82835902-49ef-4699-84aa-d7956f65395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import GlmImagePipeline\n",
    "\n",
    "# ================= 1. å‘Šè­¦å±è”½ (ä¿æŒæ¸…çˆ½) =================\n",
    "# ä½¿ç”¨ r\"\" åŸå§‹å­—ç¬¦ä¸²é¿å… SyntaxWarning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Passing `generation_config` together with.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=r\".*calling .generate\\(\\) with the `input_ids` being on a device.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Attempting to use hipBLASLt on an unsupported architecture!.*\")\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "print(\"ğŸ›¡ï¸ ç³»ç»Ÿåˆå§‹åŒ–ä¸­...\")\n",
    "\n",
    "# ================= 2. è‡ªåŠ¨ç›®å½•ç®¡ç† (æ–°å¢åŠŸèƒ½) =================\n",
    "# å®šä¹‰åŸºç¡€ä¿å­˜è·¯å¾„\n",
    "base_output_dir = \"glm_gallery\"\n",
    "\n",
    "# è·å–å½“å‰æ—¶é—´\n",
    "now = datetime.now()\n",
    "date_folder = now.strftime(\"%Y-%m-%d\")  # ä¾‹å¦‚: 2026-01-16\n",
    "time_filename = now.strftime(\"%H-%M-%S\") # ä¾‹å¦‚: 09-30-01\n",
    "\n",
    "# åˆ›å»ºæŒ‰æ—¥æœŸåˆ†ç±»çš„æ–‡ä»¶å¤¹\n",
    "save_dir = os.path.join(base_output_dir, date_folder)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ“‚ å›¾ç‰‡å°†ä¿å­˜è‡³: {save_dir}\")\n",
    "\n",
    "# ================= 3. æ˜¾å­˜æ¸…ç† =================\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# ================= 4. åŠ è½½æ¨¡å‹ =================\n",
    "model_path = \"/workspace/models/GLM-Image\"\n",
    "print(f\"ğŸš€ æ­£åœ¨åŠ è½½ GLM-Image...\")\n",
    "\n",
    "try:\n",
    "    pipe = GlmImagePipeline.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "\n",
    "    # MI50 å¿…é€‰è¡¥ä¸ (é˜²é»‘å›¾)\n",
    "    if hasattr(pipe, \"vqmodel\"):\n",
    "        pipe.vqmodel.to(dtype=torch.float32)\n",
    "    elif hasattr(pipe, \"vae\"):\n",
    "        pipe.vae.to(dtype=torch.float32)\n",
    "\n",
    "    # 32G æ˜¾å­˜å¿…é€‰ä¼˜åŒ– (CPU Offload)\n",
    "    pipe.enable_model_cpu_offload()\n",
    "    print(\"âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼\")\n",
    "\n",
    "    # ================= 5. è¿›åº¦æ¡å›è°ƒ =================\n",
    "    class ProgressBar:\n",
    "        def __init__(self, total_steps):\n",
    "            self.pbar = tqdm(total=total_steps, desc=\"ğŸ¨ ç»˜åˆ¶è¿›åº¦\", unit=\"step\")\n",
    "        \n",
    "        def __call__(self, pipe, step, timestep, callback_kwargs):\n",
    "            self.pbar.update(1)\n",
    "            return callback_kwargs\n",
    "\n",
    "    # ================= 6. ç”Ÿæˆå›¾ç‰‡ =================\n",
    "    # æç¤ºè¯\n",
    "    prompt = \"A steampunk hamster mechanic fixing a clockwork robot, brass gears, steam, highly detailed, 8k\"\n",
    "    steps = 30\n",
    "    \n",
    "    print(f\"ğŸ–Œï¸ ä»»åŠ¡å¼€å§‹: {prompt}\")\n",
    "\n",
    "    progress_callback = ProgressBar(total_steps=steps)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            height=768,\n",
    "            width=768,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=5.0,\n",
    "            callback_on_step_end=progress_callback,\n",
    "        ).images[0]\n",
    "    \n",
    "    progress_callback.pbar.close()\n",
    "\n",
    "    # ================= 7. ä¿å­˜ç»“æœ =================\n",
    "    # æ„é€ å®Œæ•´æ–‡ä»¶å\n",
    "    full_save_path = os.path.join(save_dir, f\"img_{time_filename}.png\")\n",
    "    \n",
    "    image.save(full_save_path)\n",
    "    print(f\"\\nğŸ‰ æˆåŠŸï¼å·²å½’æ¡£è‡³: {full_save_path}\")\n",
    "    \n",
    "    from IPython.display import display\n",
    "    display(image)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ å‘ç”Ÿé”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74036ef-5690-428a-bdbe-6dc2be49f2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ğŸ¨ GLM-Image (Artist)",
   "language": "python",
   "name": "env_glm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
